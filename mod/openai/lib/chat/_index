# this is a moduel to honor x-bash/chat module
# shellcheck shell=dash
xrc chat
xrc:mod:lib     openai      chat/send chat/exec

___x_cmd_openai_chat(){
    local X_help_cmd='x help -m openai chat'; help:arg:parse
    local op="$1";
    case "$op" in
        request|preparehistory|exec)
            shift; ___x_cmd_openai_chat_"$op" "$@" ;;
        *)  N=openai M="Not support such [subcmd=$op]" log:ret:64
    esac
}

___x_cmd_openai_chat_request(){
    local X_help_cmd='x help -m openai chat request'; help:arg:parse
    ___x_cmd chat --exec --provider openai "$@"
}

___x_cmd_openai_chat_request___launch(){
    local content_dir
    read -r content_dir

    ___x_cmd_openai_chat_request___trapexit(){
        openai:debug "Remove chat.running file"
        x rmrf "$content_dir/chat.running"
    }

    printf "%s\n" $$ >"$content_dir/chat.running"
    trap '___x_cmd_openai_chat_request___trapexit' EXIT

    {
        read -r model

        local requestbody
        read -r requestbody

        x retry --max 2 --interval 3 ___x_cmd_openai_chat_request___try
    } || {
        ___x_cmd_openai_chat_request___trapexit
        return 1
    }
}

___x_cmd_openai_chat_request___try(){
    openai:debug "Sending request to openai server"
    [ -z "$confirm_before_send" ] || {
        printf "%s\n" "$requestbody" | x j2y | x bat -l yml
        x ui yesno "Do your want to send this message?" || return 0
    }

    {
        ___x_cmd ccmd "$cache_time" -- \
            ___x_cmd_openai_request_generaxwtecontent "$requestbody" "$model"
    } | {
        local interative=
        if ___x_cmd_is_interactive; then interative=1; fi

        local errcode=0
        x cawk  -E content_dir,interative         \
                -m j/json,j/jiter,j/jcp                                     \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/util.awk"               \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/minion.awk"             \
                -f "$___X_CMD_ROOT_MOD/chat/lib/awk/cres.awk"               \
                -f "$___X_CMD_ROOT_MOD/openai/lib/awk/openai.awk"           \
                -f "$___X_CMD_ROOT_MOD/openai/lib/awk/openai_stream_output_util.awk"    \
                -f "$___X_CMD_ROOT_MOD/openai/lib/awk/handle_response.awk" || errcode=$?

        case $errcode in
            0)      ;;
            *)  x rmrf "$content_dir/openai.response.yml" "$content_dir/chat.response.yml" ;;
        esac
        return "$errcode"
    }
}

# x openai chat --model gpt4 -n 3 --file a.md -f b.md -f c.md --prompt english ''

# @gpt3 -n 3 -f a.md -f b.md -p en --
# @gpt3 -n 3 -f a.md -f c.jd -p cn --
# @gpt4

# using control command for this like vscode

# x chat start

# x chat start ==> create a new thread
# x chat set 3 ==> set history to 3
# @gpt3 how to understand

# @ws /start
# @ws /set 3

# x chat history cp ''

# @en
# @cn

