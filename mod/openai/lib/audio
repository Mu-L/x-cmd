# shellcheck shell=dash

# https://platform.openai.com/docs/guides/speech-to-text

___x_cmd_openai_audio(){
    param:scope     ___x_cmd_openai
    param:subcmd    ___x_cmd_openai_audio                               \
        generate          "Generates audio from the input text"         \
        translate         "Translates audio into English"               \
        transcribe        "Transcribes audio into the input language"

    param:subcmd:try
    param:run

    ___x_cmd_openai_audio _param_help_doc
    return 1
}

___x_cmd_openai_audio_generate(){
    param:scope     ___x_cmd_openai
    param:dsl       '
options:
    --model             "One of the available TTS models"               <>:String    = tts-1 tts-1-hd
    --input             "The text to generate audio for"                <>:String
    --voice             "The voice to use when generating the audio"    <>:String    = alloy echo fable onyx nova shimmer
    --response_format   "The format to audio in"                        <>="mp3"     = mp3 opus aac flac
    --speed             "The speed of the generated audio"              <>:Number="1"
    --output            "The path to the resulting audio file"          <>=""
    '
    param:run
    local gen_openai_json=""
    gen_openai_json="$(param:option2json -output)"
    openai:debug  --data "$gen_openai_json"
    local api_key="$(x openai --cfg get apikey)"
    curl https://api.openai.com/v1/audio/speech \
      -H "Authorization: Bearer $api_key" \
      -H "Content-Type: application/json" \
      -d "$gen_openai_json" \
      -o  "$output"
}

___x_cmd_openai_audio_transcribe(){
    param:scope     ___x_cmd_openai
    param:dsl       '
options:
    #1                  "The audio file path to transcribe"                                                 <>:String
    --model             "ID of the model to use. Only whisper-1 is currently available"                     <>:String    = whisper-1
    --language          "The language of the input audio"                                                   <>=""
    --prompt            "An optional text to guide the model style or continue a previous audio segment"    <>=""
    --response_format   "The format of the transcript output"                                               <>="json"   = json text srt vtt verbose_json
    --temperature       "The sampling temperature, between 0 and 1"                                         <>:Number="0"
'
    param:run
    local _file_path="$1"
    local api_key="$(x openai --cfg get apikey)"
    curl -X POST https://api.openai.com/v1/audio/transcriptions \
      -H "Authorization: Bearer $api_key" \
      -H "Content-Type: multipart/form-data" \
      -F file="@$_file_path" \
      --form model="whisper-1"
}

___x_cmd_openai_audio_translate(){
    param:scope     ___x_cmd_openai
    param:dsl       '
options:
    #1                  "The audio file path to translate"                                                  <>:String
    --model             "ID of the model to use. Only whisper-1 is currently available"                     <>:String    = whisper-1
    --language          "The language of the input audio"                                                   <>=""
    --prompt            "An optional text to guide the model style or continue a previous audio segment"    <>=""
    --response_format   "The format of the transcript output"                                               <>="json"   = json text srt vtt verbose_json
    --temperature       "The sampling temperature, between 0 and 1"                                         <>:Number="0"
'
    param:run
    local _file_path="$1"
    local api_key="$(x openai --cfg get apikey)"
    curl https://api.openai.com/v1/audio/translations \
      -H "Authorization: Bearer $api_key" \
      -H "Content-Type: multipart/form-data" \
      -F file="@$_file_path" \
      -F model="whisper-1"
}